现代很多的开发环境都是多核多线程，在申请内存的场景下，必然存在激烈的锁竞争问题。所以这次我们实现的内存池需要考虑以下几方面的问题。

1. 内存碎片问题。
2. 性能问题。
3. 多核多线程环境下，锁竞争问题。  

# 总体框架

concurrent memory pool主要由以下3个部分构成：

1. thread cache：线程缓存是每个线程独有的，用于小于64k的内存的分配，线程从这里申请内存不需要加锁，每个线程独享一个cache，这也就是这个并发线程池高效的地方。

2. central cache：中心缓存是所有线程所共享，thread cache是按需从central cache中获取的对象。central cache周期性的回收thread cache中的对象，避免一个线程占用了太多的内存，而其他线程的内存吃紧。达到内存分配在多个线程中更均衡的按需调度的目的。central cache是存在竞争的，所以从这里取内存对象是需要加锁，不过一般情况下在这里取内存对象的效率非常高，所以这里竞争不会很激烈。

   ​	居中调度：

3. page cache：页缓存是在central cache缓存上面的一层缓存，存储的内存是以页为单位存储及分配的，central cache没有内存对象时，从page cache分配出一定数量的page，并切割成定长大小的小块内存，分配给central cache。page cache会回收central cache满足条件的span对象，并且合并相邻的页，组成更大的页，缓解内存碎片的问题。  

# 1. threadcache

映射自由链表的哈希桶，尽量用原生的数据结构写，不用stl

多个线程抢占一个资源



# 1.SizeClass

对于小于64K的对象，我们统称为小对象分配，并将其划分为4个类别，我们将这种划分方式称为Size Class，通过size class可以找到对应的内存大小。Tcmalloc通过这种方式可以将内存碎片的浪费率控制在12.5%以内。为什么这么说呢？首先，Size class将64K划分为4个类别分别为：

- 8字节对齐，范围[1, 128] , 128/8 = 16
- 16字节对齐, 范围[129, 1024]
- 32字节对齐, 范围[1025, 8*1024]
- 1024字节对齐, 范围[8$*$1024+1，64$*$1024]

